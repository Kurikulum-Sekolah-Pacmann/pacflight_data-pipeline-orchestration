2024-03-24 04:55:16,680 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-24 04:55:16,689 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-24 04:55:20,552 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-24 04:55:26,751 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-24 04:55:26,858 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-24 04:55:28,015 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-24 04:55:41,456 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-24 04:55:49,423 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-24 04:55:49,423 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-24 04:55:49,483 - INFO - [pid 477001] Worker Worker(salt=1838461120, workers=1, host=DESKTOP-V42S030, username=laode, pid=477001) done      Extract()
2024-03-24 04:55:49,485 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 04:55:49,488 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-24 04:55:49,489 - DEBUG - Asking scheduler for work...
2024-03-24 04:55:49,492 - DEBUG - Pending tasks: 1
2024-03-24 04:55:49,492 - INFO - [pid 477001] Worker Worker(salt=1838461120, workers=1, host=DESKTOP-V42S030, username=laode, pid=477001) running   Load()
2024-03-24 04:55:49,493 - INFO - Read Load Query - SUCCESS
2024-03-24 04:55:53,470 - INFO - Read Extracted Data - SUCCESS
2024-03-24 04:55:53,471 - INFO - Connect to DWH - SUCCESS
2024-03-24 04:55:53,733 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-24 04:55:53,747 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-24 04:55:53,764 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-24 04:56:04,988 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-24 04:56:29,451 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-24 04:56:29,516 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-24 04:56:32,783 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-24 04:57:37,081 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-24 04:58:09,886 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-24 04:58:09,886 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-24 04:59:15,981 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-24 04:59:16,101 - INFO - [pid 477001] Worker Worker(salt=1838461120, workers=1, host=DESKTOP-V42S030, username=laode, pid=477001) done      Load()
2024-03-24 04:59:16,102 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 04:59:16,105 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-24 04:59:16,106 - DEBUG - Asking scheduler for work...
2024-03-24 04:59:16,108 - DEBUG - Done
2024-03-24 04:59:16,108 - DEBUG - There are no more tasks to run at this time
2024-03-24 04:59:16,108 - INFO - Worker Worker(salt=1838461120, workers=1, host=DESKTOP-V42S030, username=laode, pid=477001) was stopped. Shutting down Keep-Alive thread
2024-03-24 04:59:16,109 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-03-24 19:55:20,079 - ERROR - EXTRACT 'bookings.aircrafts_data' - FAILED.
2024-03-24 19:55:20,079 - INFO - Extract All Tables From Sources - FAILED
2024-03-24 19:55:20,113 - ERROR - [pid 560439] Worker Worker(salt=6663696802, workers=1, host=DESKTOP-V42S030, username=laode, pid=560439) failed    Extract()
Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 57, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 66, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'bookings.aircrafts_data' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 105, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-03-24 19:55:20,147 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 19:55:20,156 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-03-24 19:55:20,157 - DEBUG - Asking scheduler for work...
2024-03-24 19:55:20,159 - DEBUG - Done
2024-03-24 19:55:20,159 - DEBUG - There are no more tasks to run at this time
2024-03-24 19:55:20,159 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-03-24 19:55:20,159 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-03-24 19:55:20,160 - INFO - Worker Worker(salt=6663696802, workers=1, host=DESKTOP-V42S030, username=laode, pid=560439) was stopped. Shutting down Keep-Alive thread
2024-03-24 19:55:20,161 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-03-24 19:55:24,045 - ERROR - EXTRACT 'bookings.aircrafts_data' - FAILED.
2024-03-24 19:55:24,045 - INFO - Extract All Tables From Sources - FAILED
2024-03-24 19:55:24,078 - ERROR - [pid 560477] Worker Worker(salt=8739462248, workers=1, host=DESKTOP-V42S030, username=laode, pid=560477) failed    Extract()
Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 57, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 66, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'bookings.aircrafts_data' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 105, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-03-24 19:55:24,090 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 19:55:24,099 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-03-24 19:55:24,099 - DEBUG - Asking scheduler for work...
2024-03-24 19:55:24,102 - DEBUG - Done
2024-03-24 19:55:24,102 - DEBUG - There are no more tasks to run at this time
2024-03-24 19:55:24,102 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-03-24 19:55:24,102 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-03-24 19:55:24,102 - INFO - Worker Worker(salt=8739462248, workers=1, host=DESKTOP-V42S030, username=laode, pid=560477) was stopped. Shutting down Keep-Alive thread
2024-03-24 19:55:24,104 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-03-24 19:55:26,710 - ERROR - EXTRACT 'bookings.aircrafts_data' - FAILED.
2024-03-24 19:55:26,710 - INFO - Extract All Tables From Sources - FAILED
2024-03-24 19:55:26,744 - ERROR - [pid 560520] Worker Worker(salt=7780380850, workers=1, host=DESKTOP-V42S030, username=laode, pid=560520) failed    Extract()
Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 57, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 66, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'bookings.aircrafts_data' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 105, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-03-24 19:55:26,757 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 19:55:26,766 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-03-24 19:55:26,766 - DEBUG - Asking scheduler for work...
2024-03-24 19:55:26,769 - DEBUG - Done
2024-03-24 19:55:26,769 - DEBUG - There are no more tasks to run at this time
2024-03-24 19:55:26,769 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-03-24 19:55:26,769 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-03-24 19:55:26,770 - INFO - Worker Worker(salt=7780380850, workers=1, host=DESKTOP-V42S030, username=laode, pid=560520) was stopped. Shutting down Keep-Alive thread
2024-03-24 19:55:26,771 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-03-24 19:55:29,435 - ERROR - EXTRACT 'bookings.aircrafts_data' - FAILED.
2024-03-24 19:55:29,436 - INFO - Extract All Tables From Sources - FAILED
2024-03-24 19:55:29,466 - ERROR - [pid 560563] Worker Worker(salt=6500843247, workers=1, host=DESKTOP-V42S030, username=laode, pid=560563) failed    Extract()
Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 57, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 66, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'bookings.aircrafts_data' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/.venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/laode/pacmann/project/pacflight_data-pipeline-orchestration/pipeline/extract.py", line 105, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-03-24 19:55:29,481 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 19:55:29,494 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-03-24 19:55:29,495 - DEBUG - Asking scheduler for work...
2024-03-24 19:55:29,500 - DEBUG - Done
2024-03-24 19:55:29,501 - DEBUG - There are no more tasks to run at this time
2024-03-24 19:55:29,501 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-03-24 19:55:29,501 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-03-24 19:55:29,501 - INFO - Worker Worker(salt=6500843247, workers=1, host=DESKTOP-V42S030, username=laode, pid=560563) was stopped. Shutting down Keep-Alive thread
2024-03-24 19:55:29,503 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-03-24 19:58:07,304 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-24 19:58:07,315 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-24 19:58:11,235 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-24 19:58:17,160 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-24 19:58:17,311 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-24 19:58:18,655 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-24 19:58:33,761 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-24 19:58:41,826 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-24 19:58:41,826 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-24 19:58:41,865 - INFO - [pid 561704] Worker Worker(salt=9671029866, workers=1, host=DESKTOP-V42S030, username=laode, pid=561704) done      Extract()
2024-03-24 19:58:41,867 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 19:58:41,871 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-24 19:58:41,871 - DEBUG - Asking scheduler for work...
2024-03-24 19:58:41,875 - DEBUG - Pending tasks: 1
2024-03-24 19:58:41,875 - INFO - [pid 561704] Worker Worker(salt=9671029866, workers=1, host=DESKTOP-V42S030, username=laode, pid=561704) running   Load()
2024-03-24 19:58:41,877 - INFO - Read Load Query - SUCCESS
2024-03-24 19:58:45,184 - INFO - Read Extracted Data - SUCCESS
2024-03-24 19:58:45,185 - INFO - Connect to DWH - SUCCESS
2024-03-24 19:58:45,380 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-24 19:58:45,395 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-24 19:58:45,412 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-24 19:58:56,265 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-24 19:59:22,358 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-24 19:59:22,435 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-24 19:59:25,258 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-24 20:00:33,994 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-24 20:01:06,626 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-24 20:01:06,626 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-24 20:02:35,292 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-24 20:02:35,358 - INFO - [pid 561704] Worker Worker(salt=9671029866, workers=1, host=DESKTOP-V42S030, username=laode, pid=561704) done      Load()
2024-03-24 20:02:35,359 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 20:02:35,361 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-24 20:02:35,361 - DEBUG - Asking scheduler for work...
2024-03-24 20:02:35,363 - DEBUG - Done
2024-03-24 20:02:35,363 - DEBUG - There are no more tasks to run at this time
2024-03-24 20:02:35,364 - INFO - Worker Worker(salt=9671029866, workers=1, host=DESKTOP-V42S030, username=laode, pid=561704) was stopped. Shutting down Keep-Alive thread
2024-03-24 20:02:35,365 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-03-24 22:27:00,522 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-24 22:27:00,531 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-24 22:27:04,667 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-24 22:27:11,332 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-24 22:27:11,436 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-24 22:27:12,526 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-24 22:27:30,823 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-24 22:27:39,140 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-24 22:27:39,140 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-24 22:27:39,194 - INFO - [pid 578085] Worker Worker(salt=5424065923, workers=1, host=DESKTOP-V42S030, username=laode, pid=578085) done      Extract()
2024-03-24 22:27:39,195 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 22:27:39,199 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-24 22:27:39,199 - DEBUG - Asking scheduler for work...
2024-03-24 22:27:39,203 - DEBUG - Pending tasks: 1
2024-03-24 22:27:39,203 - INFO - [pid 578085] Worker Worker(salt=5424065923, workers=1, host=DESKTOP-V42S030, username=laode, pid=578085) running   Load()
2024-03-24 22:27:39,205 - INFO - Read Load Query - SUCCESS
2024-03-24 22:27:42,489 - INFO - Read Extracted Data - SUCCESS
2024-03-24 22:27:42,490 - INFO - Connect to DWH - SUCCESS
2024-03-24 22:27:42,865 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-24 22:27:42,882 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-24 22:27:42,908 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-24 22:27:53,452 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-24 22:28:14,200 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-24 22:28:14,252 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-24 22:28:16,953 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-24 22:29:28,189 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-24 22:30:00,374 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-24 22:30:00,374 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-24 22:31:12,544 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-24 22:31:12,669 - INFO - [pid 578085] Worker Worker(salt=5424065923, workers=1, host=DESKTOP-V42S030, username=laode, pid=578085) done      Load()
2024-03-24 22:31:12,670 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-24 22:31:12,673 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-24 22:31:12,673 - DEBUG - Asking scheduler for work...
2024-03-24 22:31:12,677 - DEBUG - Done
2024-03-24 22:31:12,677 - DEBUG - There are no more tasks to run at this time
2024-03-24 22:31:12,677 - INFO - Worker Worker(salt=5424065923, workers=1, host=DESKTOP-V42S030, username=laode, pid=578085) was stopped. Shutting down Keep-Alive thread
2024-03-24 22:31:12,679 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-03-25 00:38:45,331 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-25 00:38:45,342 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-25 00:38:50,493 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-25 00:38:57,514 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-25 00:38:57,655 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-25 00:38:59,220 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-25 00:39:13,939 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-25 00:39:22,258 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-25 00:39:22,258 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-25 00:39:22,296 - INFO - [pid 598022] Worker Worker(salt=1949823948, workers=1, host=DESKTOP-V42S030, username=laode, pid=598022) done      Extract()
2024-03-25 00:39:22,298 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:39:22,303 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-25 00:39:22,303 - DEBUG - Asking scheduler for work...
2024-03-25 00:39:22,306 - DEBUG - Pending tasks: 1
2024-03-25 00:39:22,307 - INFO - [pid 598022] Worker Worker(salt=1949823948, workers=1, host=DESKTOP-V42S030, username=laode, pid=598022) running   Load()
2024-03-25 00:39:22,344 - INFO - Read Load Query - SUCCESS
2024-03-25 00:39:25,628 - INFO - Read Extracted Data - SUCCESS
2024-03-25 00:39:25,629 - INFO - Connect to DWH - SUCCESS
2024-03-25 00:39:25,827 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-25 00:39:25,841 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-25 00:39:25,859 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-25 00:39:36,310 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-25 00:40:01,246 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-25 00:40:01,314 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-25 00:40:03,958 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-25 00:41:05,721 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-25 00:41:39,786 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-25 00:41:39,786 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-25 00:43:11,837 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-25 00:43:11,969 - INFO - [pid 598022] Worker Worker(salt=1949823948, workers=1, host=DESKTOP-V42S030, username=laode, pid=598022) done      Load()
2024-03-25 00:43:11,969 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:43:11,974 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-25 00:43:11,974 - DEBUG - Asking scheduler for work...
2024-03-25 00:43:11,977 - DEBUG - Done
2024-03-25 00:43:11,977 - DEBUG - There are no more tasks to run at this time
2024-03-25 00:43:11,977 - INFO - Worker Worker(salt=1949823948, workers=1, host=DESKTOP-V42S030, username=laode, pid=598022) was stopped. Shutting down Keep-Alive thread
2024-03-25 00:43:11,979 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-03-25 00:47:19,857 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-25 00:47:19,868 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-25 00:47:23,748 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-25 00:47:29,780 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-25 00:47:29,885 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-25 00:47:31,051 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-25 00:47:44,007 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-25 00:47:51,085 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-25 00:47:51,085 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-25 00:47:51,128 - INFO - [pid 600180] Worker Worker(salt=4428519687, workers=1, host=DESKTOP-V42S030, username=laode, pid=600180) done      Extract()
2024-03-25 00:47:51,129 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:47:51,134 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-25 00:47:51,134 - DEBUG - Asking scheduler for work...
2024-03-25 00:47:51,138 - DEBUG - Pending tasks: 1
2024-03-25 00:47:51,138 - INFO - [pid 600180] Worker Worker(salt=4428519687, workers=1, host=DESKTOP-V42S030, username=laode, pid=600180) running   Load()
2024-03-25 00:47:51,175 - INFO - Read Load Query - SUCCESS
2024-03-25 00:47:55,054 - INFO - Read Extracted Data - SUCCESS
2024-03-25 00:47:55,056 - INFO - Connect to DWH - SUCCESS
2024-03-25 00:47:55,314 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-25 00:47:55,327 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-25 00:47:55,340 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-25 00:48:05,106 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-25 00:48:24,785 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-25 00:48:24,866 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-25 00:48:27,383 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-25 00:49:30,512 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-25 00:50:04,205 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-25 00:50:04,205 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-25 00:51:18,219 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-25 00:51:18,309 - INFO - [pid 600180] Worker Worker(salt=4428519687, workers=1, host=DESKTOP-V42S030, username=laode, pid=600180) done      Load()
2024-03-25 00:51:18,310 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:51:18,313 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-25 00:51:18,313 - DEBUG - Asking scheduler for work...
2024-03-25 00:51:18,316 - DEBUG - Done
2024-03-25 00:51:18,316 - DEBUG - There are no more tasks to run at this time
2024-03-25 00:51:18,317 - INFO - Worker Worker(salt=4428519687, workers=1, host=DESKTOP-V42S030, username=laode, pid=600180) was stopped. Shutting down Keep-Alive thread
2024-03-25 00:51:18,318 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-03-25 00:54:31,765 - INFO - EXTRACT 'bookings.aircrafts_data' - SUCCESS.
2024-03-25 00:54:31,774 - INFO - EXTRACT 'bookings.airports_data' - SUCCESS.
2024-03-25 00:54:35,949 - INFO - EXTRACT 'bookings.bookings' - SUCCESS.
2024-03-25 00:54:42,400 - INFO - EXTRACT 'bookings.tickets' - SUCCESS.
2024-03-25 00:54:42,527 - INFO - EXTRACT 'bookings.seats' - SUCCESS.
2024-03-25 00:54:43,582 - INFO - EXTRACT 'bookings.flights' - SUCCESS.
2024-03-25 00:54:59,704 - INFO - EXTRACT 'bookings.ticket_flights' - SUCCESS.
2024-03-25 00:55:08,370 - INFO - EXTRACT 'bookings.boarding_passes' - SUCCESS.
2024-03-25 00:55:08,370 - INFO - Extract All Tables From Sources - SUCCESS
2024-03-25 00:55:08,416 - INFO - [pid 602410] Worker Worker(salt=7873719073, workers=1, host=DESKTOP-V42S030, username=laode, pid=602410) done      Extract()
2024-03-25 00:55:08,423 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:55:08,428 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-03-25 00:55:08,429 - DEBUG - Asking scheduler for work...
2024-03-25 00:55:08,433 - DEBUG - Pending tasks: 1
2024-03-25 00:55:08,433 - INFO - [pid 602410] Worker Worker(salt=7873719073, workers=1, host=DESKTOP-V42S030, username=laode, pid=602410) running   Load()
2024-03-25 00:55:08,434 - INFO - Read Load Query - SUCCESS
2024-03-25 00:55:11,829 - INFO - Read Extracted Data - SUCCESS
2024-03-25 00:55:11,830 - INFO - Connect to DWH - SUCCESS
2024-03-25 00:55:12,095 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-03-25 00:55:12,110 - INFO - LOAD 'bookings.aircrafts_data' - SUCCESS
2024-03-25 00:55:12,127 - INFO - LOAD 'bookings.airports_data' - SUCCESS
2024-03-25 00:55:23,184 - INFO - LOAD 'bookings.bookings' - SUCCESS
2024-03-25 00:55:45,800 - INFO - LOAD 'bookings.tickets' - SUCCESS
2024-03-25 00:55:45,854 - INFO - LOAD 'bookings.seats' - SUCCESS
2024-03-25 00:55:48,433 - INFO - LOAD 'bookings.flights' - SUCCESS
2024-03-25 00:56:54,069 - INFO - LOAD 'bookings.ticket_flights' - SUCCESS
2024-03-25 00:57:25,121 - INFO - LOAD 'bookings.boarding_passes' - SUCCESS
2024-03-25 00:57:25,121 - INFO - LOAD All Tables To DWH-Bookings - SUCCESS
2024-03-25 00:58:30,378 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-03-25 00:58:30,450 - INFO - [pid 602410] Worker Worker(salt=7873719073, workers=1, host=DESKTOP-V42S030, username=laode, pid=602410) done      Load()
2024-03-25 00:58:30,450 - DEBUG - 1 running tasks, waiting for next task to finish
2024-03-25 00:58:30,453 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-03-25 00:58:30,453 - DEBUG - Asking scheduler for work...
2024-03-25 00:58:30,456 - DEBUG - Done
2024-03-25 00:58:30,456 - DEBUG - There are no more tasks to run at this time
2024-03-25 00:58:30,456 - INFO - Worker Worker(salt=7873719073, workers=1, host=DESKTOP-V42S030, username=laode, pid=602410) was stopped. Shutting down Keep-Alive thread
2024-03-25 00:58:30,458 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

